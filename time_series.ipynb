{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시계열 데이터란?    \n",
    "* 시계열 : 일정시간 간격으로 배치된 데이터들의 수열\n",
    "* 시계열 데이터 : 시계열의 규칙을 갖고있는 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ex_screenshot](./image/time-series.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시계열 데이터 분석 방법\n",
    "1. ARIMA \n",
    "2. RNN (Reccurent Neural Networks)\n",
    "3. LSTM (Long Short-Term Memory models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN이란?    \n",
    "이전 입력에 대한 정보를 현재의 입력에 대한 분석에 활용하는 은닉층이 하나인 Neural Network.    \n",
    "#### 장점\n",
    "1. 순환 데이터나, 시간성(Temporal Property)등 시간성 정보를 잘 이용해야 하는 데이터 분석에 강하다.\n",
    "2. 일정하지 않은 input에 대해 분석이 가능하다.     \n",
    "\n",
    "####  단점\n",
    "1. 데이터의 time - series가 길어짐에따라 계산하는데 걸리는 시간이 증가한다.    \n",
    "    -> RNN의 간소화된 버전 GRU(Gated Recurrent Unit)를 통해 해결\n",
    "2. Vanishing Gradient Problem    \n",
    "    -> RNN과 같이 단순한 neural network 한 층 대신, 정보를 전달하는 4개의 layer를 갖는 LSTM으로 해결    \n",
    "    \n",
    "## Vanishing Gradient Problem (장기 의존성)이란?    \n",
    "Input데이터의 길이가 길어짐으로인해, time step도 마찬가지로 길어지면서, 비교적 앞부분에 대한 Hidden state정보를 전달하지 못하는 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title = RNN과 LSTM의 구조적 차이](./image/RNNnLSTM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM이란?    \n",
    "RNN의 일종으로, RNN의 장기 의존성(Long-Term Dependency)문제를 해결하기위해 제안된 방안"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title = RNN과 LSTM의 구조적 차이](./image/LSTM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "forget gate: 이전 hidden state와 t번째 input을 고려해서 어떤것을 잊어버릴지.    \n",
    "input gate: 이전 hidden state와 t번째 input을 고려해서 어떤것을 기억할지.    \n",
    "\n",
    "(핵심)Cell state update: forget gate의 값과 input gate의 값을 조합해서 최종적으로 cell state를 업데이트    \n",
    "output gate: hidden state와 t번째 input을 고려해서 다음 hidden state를 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 분석을 통해 각 세대의 사용량을 예측하여 잘못된 검침값에 대한 선제적 조치를 취하자.    \n",
    "train.csv : 2009년 1월 - 2019년 5월 / 78587가구    \n",
    "test.csv : 2009년 1월 - 2018년 5월 / 10000가구    \n",
    "submission.csv : 2018년 6월 - 2019년 5월 / 10000가구    \n",
    "분석 방법 : LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모듈 및 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 확인 및 정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape =  (78587, 126)\n",
      "test shape =  (10000, 114)\n",
      "submission shape =  (10000, 13)\n"
     ]
    }
   ],
   "source": [
    "df_1 = pd.read_csv('train.csv')\n",
    "df_2 = pd.read_csv('test.csv')\n",
    "df_3 = pd.read_csv('sample_submission.csv')\n",
    "print('train shape = ',df_1.shape)\n",
    "print('test shape = ',df_2.shape)\n",
    "print('submission shape = ',df_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', '2009-01', '2009-02', '2009-03', '2009-04', '2009-05', '2009-06',\n",
       "       '2009-07', '2009-08', '2009-09',\n",
       "       ...\n",
       "       '2018-08', '2018-09', '2018-10', '2018-11', '2018-12', '2019-01',\n",
       "       '2019-02', '2019-03', '2019-04', '2019-05'],\n",
       "      dtype='object', length=126)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x.shape :  (78587, 113)\n",
      "train_y.shape :  (78587, 12)\n"
     ]
    }
   ],
   "source": [
    "train_x = df_1.loc[:,'2009-01':'2018-05']\n",
    "train_y = df_1.loc[:,'2018-06':'2019-05']\n",
    "print('train_x.shape : ',train_x.shape)\n",
    "print('train_y.shape : ',train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape :  (78587, 113, 1)\n",
      "y_train.shape :  (78587, 12)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(train_x).reshape(train_x.shape[0], train_x.shape[1],1)\n",
    "y_train = np.array(train_y).reshape(train_y.shape[0], train_y.shape[1])\n",
    "print('X_train.shape : ',X_train.shape)\n",
    "print('y_train.shape : ',y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title = RNN과 LSTM의 구조적 차이](./image/shape.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lstm 학습 모듈 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 20)                1760      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 12)                252       \n",
      "=================================================================\n",
      "Total params: 2,012\n",
      "Trainable params: 2,012\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(20, input_shape = (113,1))) #(timestep, feature)\n",
    "model.add(Dense(12)) # output = 1\n",
    "model.compile(loss = 'mean_squared_error', optimizer ='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "78587/78587 [==============================] - 126s 2ms/step - loss: 3636.3607\n",
      "Epoch 2/100\n",
      "78587/78587 [==============================] - 125s 2ms/step - loss: 2130.5152\n",
      "Epoch 3/100\n",
      "78587/78587 [==============================] - 126s 2ms/step - loss: 1543.9169\n",
      "Epoch 4/100\n",
      "78587/78587 [==============================] - 140s 2ms/step - loss: 1288.4232\n",
      "Epoch 5/100\n",
      "78587/78587 [==============================] - 141s 2ms/step - loss: 1178.9970\n",
      "Epoch 6/100\n",
      "78587/78587 [==============================] - 141s 2ms/step - loss: 1128.4589\n",
      "Epoch 7/100\n",
      "78587/78587 [==============================] - 140s 2ms/step - loss: 1099.0105\n",
      "Epoch 8/100\n",
      "78587/78587 [==============================] - 141s 2ms/step - loss: 1079.4818\n",
      "Epoch 9/100\n",
      "78587/78587 [==============================] - 141s 2ms/step - loss: 1065.0157\n",
      "Epoch 10/100\n",
      "78587/78587 [==============================] - 141s 2ms/step - loss: 1054.2982\n",
      "Epoch 11/100\n",
      "78587/78587 [==============================] - 140s 2ms/step - loss: 1048.0265\n",
      "Epoch 12/100\n",
      "78587/78587 [==============================] - 141s 2ms/step - loss: 1042.0933\n",
      "Epoch 13/100\n",
      "78587/78587 [==============================] - 140s 2ms/step - loss: 1037.8530\n",
      "Epoch 14/100\n",
      "78587/78587 [==============================] - 141s 2ms/step - loss: 1033.7307\n",
      "Epoch 15/100\n",
      "78587/78587 [==============================] - 141s 2ms/step - loss: 1032.3471\n",
      "Epoch 16/100\n",
      "78587/78587 [==============================] - 142s 2ms/step - loss: 1028.5903\n",
      "Epoch 17/100\n",
      "78587/78587 [==============================] - 142s 2ms/step - loss: 1026.9399\n",
      "Epoch 18/100\n",
      "78587/78587 [==============================] - 142s 2ms/step - loss: 1023.7284\n",
      "Epoch 19/100\n",
      "78587/78587 [==============================] - 141s 2ms/step - loss: 1021.6862\n",
      "Epoch 20/100\n",
      "78587/78587 [==============================] - 141s 2ms/step - loss: 1020.5023\n",
      "Epoch 21/100\n",
      "78587/78587 [==============================] - 142s 2ms/step - loss: 1018.8744\n",
      "Epoch 22/100\n",
      "78587/78587 [==============================] - 141s 2ms/step - loss: 1016.8355\n",
      "Epoch 23/100\n",
      "78587/78587 [==============================] - 141s 2ms/step - loss: 1016.6267\n",
      "Epoch 24/100\n",
      "78587/78587 [==============================] - 141s 2ms/step - loss: 1014.7505\n",
      "Epoch 25/100\n",
      "78587/78587 [==============================] - 139s 2ms/step - loss: 1014.5582\n",
      "Epoch 26/100\n",
      "78587/78587 [==============================] - 139s 2ms/step - loss: 1013.2445\n",
      "Epoch 27/100\n",
      "78587/78587 [==============================] - 141s 2ms/step - loss: 1013.0003\n",
      "Epoch 28/100\n",
      "78587/78587 [==============================] - 141s 2ms/step - loss: 1011.6578\n",
      "Epoch 29/100\n",
      "78587/78587 [==============================] - 141s 2ms/step - loss: 1011.2307\n",
      "Epoch 30/100\n",
      "74272/78587 [===========================>..] - ETA: 7s - loss: 1010.2914"
     ]
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor = 'loss', patience = 1, verbose = 1)\n",
    "\n",
    "hist = model.fit(X_train, y_train, epochs = 100, \n",
    "         batch_size = 32, verbose = 1, callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
